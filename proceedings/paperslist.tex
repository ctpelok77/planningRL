%% Use pp with these parameters:
%%   - paper number
%%   - Authors as they should appear in the table of contents
%%   - Title for the table of contents


\pp{1}{Tom Silver and Rohan Chitnis}{PDDLGym: Gym Environments from PDDL Problems}
\pp{3}{Michaela Urbanovsk\'{a}, Jan B\'{i}m, Leah Chrestien, Anton\'{i}n Komenda and Tom\'{a}\v{s} Pevn\'{y}}{Model-free Automated Planning Using Neural Networks}
\pp{5}{Or Rivlin, Tamir Hazan and Erez Karpas}{Generalized Planning With Deep Reinforcement Learning}
\pp{8}{Tomas Brazdil, Krishnendu Chatterjee, Petr Novotn\'{y} and Ji\v{r}\'{i} Vahala}{Reinforcement Learning of Risk-Constrained Policies in Markov Decision Processes (Extended Abstract)}
\pp{9}{Kevin Osanlou, Jeremy Frank, J. Benton, Andrei Bursuc, Christophe Guettier, Eric Jacopin and Tristan Cazenave}{Time-based Dynamic Controllability of Disjunctive Temporal Networks with Uncertainty: A Tree Search Approach with Graph Neural Network Guidance}
\pp{10}{Andrea Micheli and Alessandro Valentini}{Synthesis of Search Heuristics for Temporal Planning via Reinforcement Learning}
\pp{11}{Thomas Moerland, Joost Broekens and Catholijn Jonker}{A Framework for Reinforcement Learning and Planning: Extended Abstract}
\pp{12}{Thomas Moerland, Anna Deichler, Simone Baldi, Joost Broekens and Catholijn Jonker}{Think Neither Too Fast Nor Too Slow: The Computational Trade-off Between Planning And Reinforcement Learning}
\pp{13}{David Speck, Andr\'{e} Biedenkapp, Frank Hutter, Robert Mattm\"{u}ller and Marius Lindauer}{Learning Heuristic Selection with Dynamic Algorithm Configuration}
\pp{14}{Yat Long Lo, Jia Pan and Albert Y.S. Lam}{Knowing When To Look Back: Bidirectional Rollouts in Dyna-style Planning}
\pp{15}{Guillaume Matheron, Olivier Sigaud and Nicolas Perrin}{PBCS: Efficient Exploration and Exploitation Using a Synergy between Reinforcement Learning and Motion Planning}
\pp{16}{Xinyi Xu, Tiancheng Huang, Pengfei Wei, Akshay Narayan and Tze-Yun Leong}{Hierarchical Reinforcement Learning in StarCraft II with Human Expertise in Subgoals Selection}
\pp{17}{Sankalp Garg, Aniket Bajpai and Mausam Mausam}{Symbolic Network: Generalized Neural Policies for Relational MDPs}
\pp{18}{Brendan Juba, Hai Le and Roni Stern}{Safe Learning of Lifted Action Models}
\pp{19}{Patrick Ferber, Malte Helmert and Joerg Hoffmann}{Reinforcement Learning for Planning Heuristics}
\pp{20}{Eric Benhamou, David Saltiel, Sandrine Ungari and Abhishek Mukhopadhyayg}{Bridging the gap between Markowitz planning and deep reinforcement learning}
\pp{21}{Frederik Drachmann, Andrea Dittadi and Thomas Bolander}{Planning from Pixels in Atari with Learned Symbolic Representations}
\pp{22}{Giorgio Angelotti, Nicolas Drougard and Caroline Ponzoni Carvalho Chanel}{Offline Learning for Planning: A Summary}
\pp{23}{Maximilian Fickert, Tianyi Gu, Leonhard Staut, Sai Lekyang, Wheeler Ruml, Joerg Hoffmann and Marek Petrik}{Real-time Planning as Data-driven Decision-making}