\documentclass[10pt]{article}

\newcommand{\commentout}[1]{}
\usepackage[colorlinks=true,urlcolor=blue,citecolor=blue,pdfstartview=FitH]{hyperref}


\begin{document}

\title{ICAPS 2020 Workshop on \\ Bridging the Gap Between AI Planning and Reinforcement Learning (PRL)\\ \vspace*{0.7cm} Workshop Proposal
}
\date{}

\author{}

\maketitle


We propose to start a new workshop series at ICAPS 2020. This workshop aims to
bridge the gap between the AI planning and Reinforcement Learning communities
that focus on similar sequential decision-making problems. Currently, these
communities sometimes remain somewhat unaware of each other on specific
problems, techniques, methodologies, and evaluation.

\section*{Workshop Description}

The workshop seeks submissions that are relevant to both Reinforcement Learning
and Planning. 





%\newpage

\section*{Relevance to ICAPS 2020}
ICAPS 2020 has seen a significant increase in the number of submissions on
Reinforcement Learning, indicating an increased interest from the RL community
towards AI Planning.

\section*{Topics of interest / questions}

\begin{itemize}
\item How do concepts from each of these fields translate to the other?
%
% \item 
%
\item What is the impact of methods on how it would be used in practice? For
instance, whether the problem to solve is seen only once by the solver, or if
the solver would solve variations of the same problem for weeks or years. 
%
\item What is the right way of evaluating the impact of ML-based methods? Is the
methodology used in the learning track of the IPC useful and attractive?
%
\item Is there an interesting middle ground between capturing action dynamics
symbolically and model-free RL? Are there interesting domains that exhibit a
structure that can be partially captured with a symbolic model? How can that be
exploited in practice?
%
\item Factored-blackbox planning is a planning problem formulated as a simulator
where states are meaningful factors, and applying actions lead to a new state.
Some planning algorithms can achieve state of the art on IPC benchmarks, where
the action description has more information (PDDL). Is that setting interesting
for the RL community? How should methods be evaluated?
\end{itemize}

\section*{Workshop Format}

The workshop is planned to have a full 1-day format, but the precise format is
to be decided as a function of the contributions received. We strive to have two
types of presentations: long and short (30 and 15 minutes, including
discussion), 1-2 invited talks, as well as 1-2 dedicated discussion sessions
where the audience members are encouraged to participate.

We would like to reduce the reviewing load of the community by not having a
program committee. Acceptance decisions will be made directly by the organizers.
We expect to have around 10-20 submissions, which can easily be handled by us,
particularly considering that reviewing for workshops is generally light.
Between us, we have sufficient competence in the topic of the workshop to make
informed decisions, but should the need arise, we can call on additional
reviewing expertise.

\section*{Possible Invited Speakers}

\begin{itemize}
  \item Hector Geffner
  \item Leslie Kaelbling
  \item Marc Bellemare
  \item Murray Shanahan
  \item Peter Stone 
  \item George Konidaris
\end{itemize}


\section*{Organizers}

\begin{itemize}

\item \href{placeholder}{Alan Fern}
  (\href{mailto:placeholder}{placeholder})\\
  


\item \href{placeholder}{Vicen\c{c} G\'{o}mez}
  (\href{mailto:placeholder}{placeholder})\\



\item \href{placeholder}{Anders Jonsson}
  (\href{mailto:placeholder}{placeholder})\\
  
  
\item \href{https://resedit.watson.ibm.com/researcher/view.php?person=ibm-Michael.Katz1}{Michael Katz}
 (\href{mailto:michael.katz1@ibm.com}{michael.katz1@ibm.com})\\
 Michael is a researcher at IBM T.J. Watson Research Center, NY, USA. His
 primary research interest is in heuristic search for domain independent planning.
 He received his PhD for a dissertation on heuristics for domain independent
 planning from Technion in 2010.
 He was a co-organizer of the 2011, 2013, 2014, 2015, 2016, and 2018 H(S)DIP
 workshops.


\item \href{http://hectorpalacios.net/}{Hector Palacios}
  (\href{mailto:hectorpal@gmail.com}{hectorpal@gmail.com})\\

\item \href{http://d3m.mie.utoronto.ca}{Scott Sanner}
  (\href{mailto:ssanner@mie.utoronto.ca}{ssanner@mie.utoronto.ca})\\
Scott Sanner is an Assistant Professor in Industrial Engineering at the
University of Toronto and Cross-appointed in Computer Science.  Scott earned a
PhD in Computer Science from the University of Toronto (2008).  Scottâ€™s research
spans a broad range of topics covering Machine Learning, Artificial
Intelligence, and Operations Research; he was a co-recipient of the 2014 AIJ
Prominent Paper Award and the 2016 Kikuchi-Karlaftis Best Paper Award of the
Transport Research Board.  Scott has served as Program Co-chair for the 26th
International Conference on Automated Planning and Scheduling (ICAPS 2016) and
previously organized workshops at AAAI (2016, 2017), ICAPS (2010, 2012, 2015),
NIPS (2011), and EWRL (2011).
  




% \item \href{placeholder}{placeholder}
%   (\href{mailto:placeholder}{placeholder})\\

  
\end{itemize}

\section*{Audience}

The audience of this workshop is researchers that are interested in both
planning and reinforcement learning.
%
Based on our experience with new workshops, we expect to see a moderate
participation at first. We estimate an audience of about 15 participants.  

\end{document}
